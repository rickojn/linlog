
1 names loaded

creating model ...

... model created.

initialising model ....

model initialised ....

model before training:

embedding table:
token 0:	embedding: 1.000000 	 1.000000 
token 1:	embedding: 1.000000 	 1.000000 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  
neuron 1, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  
neuron 2, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  
neuron 3, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  
neuron 4, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 1, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  

epoch 0 


logit 0: 5.975274 

logit 1: 5.975274 

logit 2: 5.975274 

logit 3: 5.975274 

correct index is 1

prob [0] = 0.500000

prob [1] = 0.500000

correct index is 2

prob [2] = 0.500000

prob [3] = 0.500000

loss before back = 0.693147

 backwards pass ...

 0.500000  -0.500000 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.500000  0.500000 

 total delta = -0.000000 

 bias [1] = 1.000000  delta = -0.000000 

 neuron 0, weight 0 batch 0 grad: 0.497527

 neuron 0, weight 0 batch 1 grad: -2.987637

weight delta[0] = -2.490109

 neuron 0, weight 1 batch 0 grad: 0.497527

 neuron 0, weight 1 batch 1 grad: -2.987637

weight delta[1] = -2.490109

 neuron 0, weight 2 batch 0 grad: 0.497527

 neuron 0, weight 2 batch 1 grad: -2.987637

weight delta[2] = -2.490109

 neuron 0, weight 3 batch 0 grad: 0.497527

 neuron 0, weight 3 batch 1 grad: -2.987637

weight delta[3] = -2.490109

 neuron 0, weight 4 batch 0 grad: 0.497527

 neuron 0, weight 4 batch 1 grad: -0.250000

weight delta[4] = 0.247527

 neuron 1, weight 0 batch 0 grad: -0.497527

 neuron 1, weight 0 batch 1 grad: 0.250000

weight delta[0] = -0.247527

 neuron 1, weight 1 batch 0 grad: -0.497527

 neuron 1, weight 1 batch 1 grad: 0.250000

weight delta[1] = -0.247527

 neuron 1, weight 2 batch 0 grad: -0.497527

 neuron 1, weight 2 batch 1 grad: 0.250000

weight delta[2] = -0.247527

 neuron 1, weight 3 batch 0 grad: -0.497527

 neuron 1, weight 3 batch 1 grad: 0.250000

weight delta[3] = -0.247527

 neuron 1, weight 4 batch 0 grad: -0.497527

 neuron 1, weight 4 batch 1 grad: -0.250000

weight delta[4] = -0.747527

 0.500000  -0.500000 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.500000  0.500000 

 total delta = -0.000000 

 bias [1] = 1.000000  delta = -0.000000 

embedding table:
token 0:	embedding: 1.100000 	 1.100000 
token 1:	embedding: 1.050000 	 1.050000 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 1.031684  	Weight 1: 1.031684  
neuron 1, biase 1.000000
	Weight 0: 1.010631  	Weight 1: 1.010631  
neuron 2, biase 1.000000
	Weight 0: 1.031684  	Weight 1: 1.031684  
neuron 3, biase 1.000000
	Weight 0: 1.010631  	Weight 1: 1.010631  
neuron 4, biase 1.000000
	Weight 0: 1.021157  	Weight 1: 1.021157  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 0.875495  	Weight 1: 0.875495  	Weight 2: 0.875495  	Weight 3: 0.875495  	Weight 4: 1.012376  
neuron 1, bias 1.000000
	Weight 0: 0.987624  	Weight 1: 0.987624  	Weight 2: 0.987624  	Weight 3: 0.987624  	Weight 4: 0.962624  


logit 0: 5.500696 

logit 1: 5.898252 

logit 2: 5.499230 

logit 3: 5.896657 


correct index is 1

prob [0] = 0.401900

prob [1] = 0.598100

correct index is 2

prob [2] = 0.401931

prob [3] = 0.598069

 new loss is greater: 0.712736
