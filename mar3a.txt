
1 names loaded

creating model ...

... model created.

initialising model ....

model initialised ....

model before training:

embedding table:
token 0:	embedding: 1.000000 	 1.000000 
token 1:	embedding: 1.000000 	 1.000000 
token 2:	embedding: 1.000000 	 1.000000 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  
neuron 1, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  
neuron 2, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  
neuron 3, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  
neuron 4, biase 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 1, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 2, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  

epoch 0 


logit 0: 5.996647 

logit 1: 5.996647 

logit 2: 5.996647 

logit 3: 5.996647 

correct index is 1

prob [0] = 0.333333

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333333

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333333

prob [7] = 0.333333

prob [8] = 0.333333

loss before back = 1.098612

 backwards pass ...
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 6
offset_batch_embedding_element: 7
offset_batch_embedding_element: 8
offset_batch_embedding_element: 9
offset_batch_embedding_element: 14
offset_batch_embedding_element: 15
offset_batch_embedding_element: 16
offset_batch_embedding_element: 17

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

 neuron 0, weight 0 batch 0 grad: 0.333110

 neuron 0, weight 0 batch 1 grad: 0.333110

 neuron 0, weight 0 batch 2 grad: -0.666220

weight delta[0] = 0.000000

 neuron 0, weight 1 batch 0 grad: 0.333110

 neuron 0, weight 1 batch 1 grad: 0.333110

 neuron 0, weight 1 batch 2 grad: -0.666220

weight delta[1] = 0.000000

 neuron 0, weight 2 batch 0 grad: 0.333110

 neuron 0, weight 2 batch 1 grad: 0.333110

 neuron 0, weight 2 batch 2 grad: -0.666220

weight delta[2] = 0.000000

 neuron 0, weight 3 batch 0 grad: 0.333110

 neuron 0, weight 3 batch 1 grad: 0.333110

 neuron 0, weight 3 batch 2 grad: -0.666220

weight delta[3] = 0.000000

 neuron 0, weight 4 batch 0 grad: 0.333110

 neuron 0, weight 4 batch 1 grad: 0.333110

 neuron 0, weight 4 batch 2 grad: -0.666220

weight delta[4] = 0.000000

 neuron 1, weight 0 batch 0 grad: -0.666220

 neuron 1, weight 0 batch 1 grad: 0.333110

 neuron 1, weight 0 batch 2 grad: 0.333110

weight delta[0] = 0.000000

 neuron 1, weight 1 batch 0 grad: -0.666220

 neuron 1, weight 1 batch 1 grad: 0.333110

 neuron 1, weight 1 batch 2 grad: 0.333110

weight delta[1] = 0.000000

 neuron 1, weight 2 batch 0 grad: -0.666220

 neuron 1, weight 2 batch 1 grad: 0.333110

 neuron 1, weight 2 batch 2 grad: 0.333110

weight delta[2] = 0.000000

 neuron 1, weight 3 batch 0 grad: -0.666220

 neuron 1, weight 3 batch 1 grad: 0.333110

 neuron 1, weight 3 batch 2 grad: 0.333110

weight delta[3] = 0.000000

 neuron 1, weight 4 batch 0 grad: -0.666220

 neuron 1, weight 4 batch 1 grad: 0.333110

 neuron 1, weight 4 batch 2 grad: 0.333110

weight delta[4] = 0.000000

 neuron 2, weight 0 batch 0 grad: 0.333110

 neuron 2, weight 0 batch 1 grad: -0.666220

 neuron 2, weight 0 batch 2 grad: 0.333110

weight delta[0] = 0.000000

 neuron 2, weight 1 batch 0 grad: 0.333110

 neuron 2, weight 1 batch 1 grad: -0.666220

 neuron 2, weight 1 batch 2 grad: 0.333110

weight delta[1] = 0.000000

 neuron 2, weight 2 batch 0 grad: 0.333110

 neuron 2, weight 2 batch 1 grad: -0.666220

 neuron 2, weight 2 batch 2 grad: 0.333110

weight delta[2] = 0.000000

 neuron 2, weight 3 batch 0 grad: 0.333110

 neuron 2, weight 3 batch 1 grad: -0.666220

 neuron 2, weight 3 batch 2 grad: 0.333110

weight delta[3] = 0.000000

 neuron 2, weight 4 batch 0 grad: 0.333110

 neuron 2, weight 4 batch 1 grad: -0.666220

 neuron 2, weight 4 batch 2 grad: 0.333110

weight delta[4] = 0.000000

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

embedding table:
token 0:	embedding: 0.999330 	 0.999330 
token 1:	embedding: 0.999776 	 0.999776 
token 2:	embedding: 0.999776 	 0.999776 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 0.999866  	Weight 1: 0.999866  	Weight 2: 0.999866  	Weight 3: 1.000000  
neuron 1, biase 1.000000
	Weight 0: 0.999911  	Weight 1: 0.999911  	Weight 2: 0.999911  	Weight 3: 1.000000  
neuron 2, biase 1.000000
	Weight 0: 0.999911  	Weight 1: 0.999911  	Weight 2: 0.999911  	Weight 3: 1.000000  
neuron 3, biase 1.000000
	Weight 0: 0.999911  	Weight 1: 0.999911  	Weight 2: 0.999911  	Weight 3: 1.000000  
neuron 4, biase 1.000000
	Weight 0: 0.999911  	Weight 1: 0.999911  	Weight 2: 0.999911  	Weight 3: 1.000000  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 1, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 2, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  


logit 0: 5.996631 

logit 1: 5.996631 

logit 2: 5.996631 

logit 3: 5.996634 


correct index is 1

prob [0] = 0.333333

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333333

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333333

prob [7] = 0.333333

prob [8] = 0.333333

loss after back = 1.098612

epoch 1 


logit 0: 5.996631 

logit 1: 5.996631 

logit 2: 5.996631 

logit 3: 5.996634 

correct index is 1

prob [0] = 0.333333

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333333

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333333

prob [7] = 0.333333

prob [8] = 0.333333

loss before back = 1.098612

 backwards pass ...
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 6
offset_batch_embedding_element: 7
offset_batch_embedding_element: 8
offset_batch_embedding_element: 9
offset_batch_embedding_element: 14
offset_batch_embedding_element: 15
offset_batch_embedding_element: 16
offset_batch_embedding_element: 17

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

 neuron 0, weight 0 batch 0 grad: 0.333109

 neuron 0, weight 0 batch 1 grad: 0.333109

 neuron 0, weight 0 batch 2 grad: -0.666218

weight delta[0] = -0.000001

 neuron 0, weight 1 batch 0 grad: 0.333109

 neuron 0, weight 1 batch 1 grad: 0.333109

 neuron 0, weight 1 batch 2 grad: -0.666218

weight delta[1] = -0.000001

 neuron 0, weight 2 batch 0 grad: 0.333109

 neuron 0, weight 2 batch 1 grad: 0.333109

 neuron 0, weight 2 batch 2 grad: -0.666218

weight delta[2] = -0.000001

 neuron 0, weight 3 batch 0 grad: 0.333109

 neuron 0, weight 3 batch 1 grad: 0.333109

 neuron 0, weight 3 batch 2 grad: -0.666218

weight delta[3] = -0.000001

 neuron 0, weight 4 batch 0 grad: 0.333109

 neuron 0, weight 4 batch 1 grad: 0.333109

 neuron 0, weight 4 batch 2 grad: -0.666218

weight delta[4] = -0.000001

 neuron 1, weight 0 batch 0 grad: -0.666217

 neuron 1, weight 0 batch 1 grad: 0.333109

 neuron 1, weight 0 batch 2 grad: 0.333109

weight delta[0] = 0.000001

 neuron 1, weight 1 batch 0 grad: -0.666217

 neuron 1, weight 1 batch 1 grad: 0.333109

 neuron 1, weight 1 batch 2 grad: 0.333109

weight delta[1] = 0.000001

 neuron 1, weight 2 batch 0 grad: -0.666217

 neuron 1, weight 2 batch 1 grad: 0.333109

 neuron 1, weight 2 batch 2 grad: 0.333109

weight delta[2] = 0.000001

 neuron 1, weight 3 batch 0 grad: -0.666217

 neuron 1, weight 3 batch 1 grad: 0.333109

 neuron 1, weight 3 batch 2 grad: 0.333109

weight delta[3] = 0.000001

 neuron 1, weight 4 batch 0 grad: -0.666217

 neuron 1, weight 4 batch 1 grad: 0.333109

 neuron 1, weight 4 batch 2 grad: 0.333109

weight delta[4] = 0.000001

 neuron 2, weight 0 batch 0 grad: 0.333109

 neuron 2, weight 0 batch 1 grad: -0.666218

 neuron 2, weight 0 batch 2 grad: 0.333109

weight delta[0] = 0.000000

 neuron 2, weight 1 batch 0 grad: 0.333109

 neuron 2, weight 1 batch 1 grad: -0.666218

 neuron 2, weight 1 batch 2 grad: 0.333109

weight delta[1] = 0.000000

 neuron 2, weight 2 batch 0 grad: 0.333109

 neuron 2, weight 2 batch 1 grad: -0.666218

 neuron 2, weight 2 batch 2 grad: 0.333109

weight delta[2] = 0.000000

 neuron 2, weight 3 batch 0 grad: 0.333109

 neuron 2, weight 3 batch 1 grad: -0.666218

 neuron 2, weight 3 batch 2 grad: 0.333109

weight delta[3] = 0.000000

 neuron 2, weight 4 batch 0 grad: 0.333109

 neuron 2, weight 4 batch 1 grad: -0.666218

 neuron 2, weight 4 batch 2 grad: 0.333109

weight delta[4] = 0.000000

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

embedding table:
token 0:	embedding: 0.997315 	 0.997315 
token 1:	embedding: 0.999105 	 0.999105 
token 2:	embedding: 0.999105 	 0.999105 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 0.999731  	Weight 1: 0.999731  	Weight 2: 0.999731  	Weight 3: 1.000000  
neuron 1, biase 1.000000
	Weight 0: 0.999821  	Weight 1: 0.999821  	Weight 2: 0.999821  	Weight 3: 1.000000  
neuron 2, biase 1.000000
	Weight 0: 0.999821  	Weight 1: 0.999821  	Weight 2: 0.999821  	Weight 3: 1.000000  
neuron 3, biase 1.000000
	Weight 0: 0.999821  	Weight 1: 0.999821  	Weight 2: 0.999821  	Weight 3: 1.000000  
neuron 4, biase 1.000000
	Weight 0: 0.999821  	Weight 1: 0.999821  	Weight 2: 0.999821  	Weight 3: 1.000000  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 1, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 2, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  


logit 0: 5.996588 

logit 1: 5.996588 

logit 2: 5.996588 

logit 3: 5.996600 


correct index is 1

prob [0] = 0.333333

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333333

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333333

prob [7] = 0.333333

prob [8] = 0.333333

loss after back = 1.098612

epoch 2 


logit 0: 5.996588 

logit 1: 5.996588 

logit 2: 5.996588 

logit 3: 5.996600 

correct index is 1

prob [0] = 0.333333

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333333

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333333

prob [7] = 0.333333

prob [8] = 0.333333

loss before back = 1.098612

 backwards pass ...
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 0
offset_batch_embedding_element: 1
offset_batch_embedding_element: 6
offset_batch_embedding_element: 7
offset_batch_embedding_element: 8
offset_batch_embedding_element: 9
offset_batch_embedding_element: 14
offset_batch_embedding_element: 15
offset_batch_embedding_element: 16
offset_batch_embedding_element: 17

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

 neuron 0, weight 0 batch 0 grad: 0.333106

 neuron 0, weight 0 batch 1 grad: 0.333107

 neuron 0, weight 0 batch 2 grad: -0.666215

weight delta[0] = -0.000002

 neuron 0, weight 1 batch 0 grad: 0.333106

 neuron 0, weight 1 batch 1 grad: 0.333107

 neuron 0, weight 1 batch 2 grad: -0.666215

weight delta[1] = -0.000002

 neuron 0, weight 2 batch 0 grad: 0.333106

 neuron 0, weight 2 batch 1 grad: 0.333107

 neuron 0, weight 2 batch 2 grad: -0.666215

weight delta[2] = -0.000002

 neuron 0, weight 3 batch 0 grad: 0.333106

 neuron 0, weight 3 batch 1 grad: 0.333107

 neuron 0, weight 3 batch 2 grad: -0.666215

weight delta[3] = -0.000002

 neuron 0, weight 4 batch 0 grad: 0.333106

 neuron 0, weight 4 batch 1 grad: 0.333107

 neuron 0, weight 4 batch 2 grad: -0.666215

weight delta[4] = -0.000002

 neuron 1, weight 0 batch 0 grad: -0.666211

 neuron 1, weight 0 batch 1 grad: 0.333107

 neuron 1, weight 0 batch 2 grad: 0.333107

weight delta[0] = 0.000003

 neuron 1, weight 1 batch 0 grad: -0.666212

 neuron 1, weight 1 batch 1 grad: 0.333107

 neuron 1, weight 1 batch 2 grad: 0.333108

weight delta[1] = 0.000002

 neuron 1, weight 2 batch 0 grad: -0.666212

 neuron 1, weight 2 batch 1 grad: 0.333107

 neuron 1, weight 2 batch 2 grad: 0.333108

weight delta[2] = 0.000002

 neuron 1, weight 3 batch 0 grad: -0.666212

 neuron 1, weight 3 batch 1 grad: 0.333107

 neuron 1, weight 3 batch 2 grad: 0.333108

weight delta[3] = 0.000002

 neuron 1, weight 4 batch 0 grad: -0.666212

 neuron 1, weight 4 batch 1 grad: 0.333107

 neuron 1, weight 4 batch 2 grad: 0.333108

weight delta[4] = 0.000002

 neuron 2, weight 0 batch 0 grad: 0.333106

 neuron 2, weight 0 batch 1 grad: -0.666213

 neuron 2, weight 0 batch 2 grad: 0.333107

weight delta[0] = 0.000000

 neuron 2, weight 1 batch 0 grad: 0.333106

 neuron 2, weight 1 batch 1 grad: -0.666213

 neuron 2, weight 1 batch 2 grad: 0.333108

weight delta[1] = 0.000000

 neuron 2, weight 2 batch 0 grad: 0.333106

 neuron 2, weight 2 batch 1 grad: -0.666213

 neuron 2, weight 2 batch 2 grad: 0.333108

weight delta[2] = 0.000000

 neuron 2, weight 3 batch 0 grad: 0.333106

 neuron 2, weight 3 batch 1 grad: -0.666213

 neuron 2, weight 3 batch 2 grad: 0.333108

weight delta[3] = 0.000000

 neuron 2, weight 4 batch 0 grad: 0.333106

 neuron 2, weight 4 batch 1 grad: -0.666213

 neuron 2, weight 4 batch 2 grad: 0.333108

weight delta[4] = 0.000000

 0.333333  0.333333  -0.666667 

 total delta = 0.000000 

 bias [0] = 1.000000  delta = 0.000000 

 -0.666667  0.333333  0.333333 

 total delta = 0.000000 

 bias [1] = 1.000000  delta = 0.000000 

 0.333333  -0.666667  0.333333 

 total delta = 0.000000 

 bias [2] = 1.000000  delta = 0.000000 

embedding table:
token 0:	embedding: 0.993275 	 0.993276 
token 1:	embedding: 0.997758 	 0.997758 
token 2:	embedding: 0.997758 	 0.997760 

hidden layer: 
neuron 0, biase 1.000000
	Weight 0: 0.999596  	Weight 1: 0.999596  	Weight 2: 0.999596  	Weight 3: 1.000000  
neuron 1, biase 1.000000
	Weight 0: 0.999730  	Weight 1: 0.999730  	Weight 2: 0.999730  	Weight 3: 1.000000  
neuron 2, biase 1.000000
	Weight 0: 0.999730  	Weight 1: 0.999730  	Weight 2: 0.999730  	Weight 3: 1.000000  
neuron 3, biase 1.000000
	Weight 0: 0.999730  	Weight 1: 0.999730  	Weight 2: 0.999730  	Weight 3: 1.000000  
neuron 4, biase 1.000000
	Weight 0: 0.999730  	Weight 1: 0.999730  	Weight 2: 0.999730  	Weight 3: 1.000000  

output layer: 
neuron 0, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 1, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  
neuron 2, bias 1.000000
	Weight 0: 1.000000  	Weight 1: 1.000000  	Weight 2: 1.000000  	Weight 3: 1.000000  	Weight 4: 1.000000  


logit 0: 5.996503 

logit 1: 5.996502 

logit 2: 5.996502 

logit 3: 5.996534 


correct index is 1

prob [0] = 0.333334

prob [1] = 0.333333

prob [2] = 0.333333

correct index is 5

prob [3] = 0.333334

prob [4] = 0.333333

prob [5] = 0.333333

correct index is 6

prob [6] = 0.333334

prob [7] = 0.333333

prob [8] = 0.333333

 new loss is greater: 1.098612
